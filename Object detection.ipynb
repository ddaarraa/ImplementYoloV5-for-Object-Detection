{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f577c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import  transforms \n",
    "import torch\n",
    "from torch import no_grad\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500560ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/darasroin/.cache/torch/hub/ultralytics_yolov5_master\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "YOLOv5 ðŸš€ 2024-3-5 Python-3.9.12 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "model_ = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_.eval()\n",
    "\n",
    "for name, param in model_.named_parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"done\")\n",
    "def model(x):\n",
    "    with torch.no_grad():\n",
    "        yhat = model_(x)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c78777",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # Resize the image to (224, 224)\n",
    "#     transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "# ])\n",
    "def save_RAM(image_=False):\n",
    "    global frame, img, pred\n",
    "    torch.cuda.empty_cache()\n",
    "#     del(img)\n",
    "    del(pred)\n",
    "    del(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb49c964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns/detect/exp6514\u001b[0m\n",
      "Saved results to runs/detect/exp6514\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6515\u001b[0m\n",
      "Saved results to runs/detect/exp6515\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6516\u001b[0m\n",
      "Saved results to runs/detect/exp6516\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6517\u001b[0m\n",
      "Saved results to runs/detect/exp6517\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6518\u001b[0m\n",
      "Saved results to runs/detect/exp6518\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6519\u001b[0m\n",
      "Saved results to runs/detect/exp6519\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6520\u001b[0m\n",
      "Saved results to runs/detect/exp6520\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6521\u001b[0m\n",
      "Saved results to runs/detect/exp6521\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6522\u001b[0m\n",
      "Saved results to runs/detect/exp6522\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6523\u001b[0m\n",
      "Saved results to runs/detect/exp6523\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6524\u001b[0m\n",
      "Saved results to runs/detect/exp6524\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6525\u001b[0m\n",
      "Saved results to runs/detect/exp6525\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6526\u001b[0m\n",
      "Saved results to runs/detect/exp6526\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6527\u001b[0m\n",
      "Saved results to runs/detect/exp6527\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6528\u001b[0m\n",
      "Saved results to runs/detect/exp6528\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6529\u001b[0m\n",
      "Saved results to runs/detect/exp6529\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6530\u001b[0m\n",
      "Saved results to runs/detect/exp6530\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6531\u001b[0m\n",
      "Saved results to runs/detect/exp6531\n",
      "\n",
      "Saved 1 image to \u001b[1mruns/detect/exp6532\u001b[0m\n",
      "Saved results to runs/detect/exp6532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a VideoCapture object to capture video from the webcam\n",
    "cap = cv2.VideoCapture(1)  # 0 for the default webcam\n",
    "\n",
    "try :\n",
    "    while True:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "    #     frame = Image.fromarray(frame)\n",
    "    #     img = transform(frame)\n",
    "        pred = model(frame)\n",
    "        output = pred.crop()\n",
    "    #     print(len(output))\n",
    "    #     pred_thresh=get_predictions(pred,threshold=0.97)\n",
    "    #     draw_box(pred_thresh,img,rect_th= 1,text_size= 1,text_th=1)\n",
    "    #     print(pred)\n",
    "        \n",
    "         \n",
    "        if(len(output)!=0) :\n",
    "            \n",
    "            for i in range(len(output)):\n",
    "                accuracy = output[i]['label']\n",
    "                if(float(accuracy[len(accuracy)-4:]) > 0.5) :\n",
    "                    cv2.rectangle(frame, (int(output[i]['box'][0]), int(output[i]['box'][1])), (int(output[i]['box'][2]), int(output[i]['box'][3])), (0, 255, 0), 1)\n",
    "                    cv2.putText(frame,output[i]['label'], (int(output[i]['box'][0]), int(output[i]['box'][1])) ,  cv2.FONT_HERSHEY_SIMPLEX, 3, (255,0,0),thickness=3)\n",
    "\n",
    "        # Check if the frame was successfully read\n",
    "        if not ret:\n",
    "            break\n",
    "        del output       \n",
    "        # Display the frame in a window\n",
    "        cv2.imshow(\"Frame\", frame )\n",
    "    #     del pred_thresh\n",
    "        save_RAM(image_=True)\n",
    "    #     # Check for the 'q' key to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        pass\n",
    "except KeyboardInterrupt :\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# Release the VideoCapture object and close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_box(predicted_classes,image,rect_th= 10,text_size= 3,text_th=3):\n",
    "#     \"\"\"\n",
    "#     draws box around each object \n",
    "    \n",
    "#     predicted_classes: a list where each element contains a tuple that corresponds to information about  the different objects; Each element includes a tuple with the class name, probability of belonging to that class and the coordinates of the bounding box corresponding to the object \n",
    "#     image : frozen surface \n",
    "   \n",
    "#     \"\"\"\n",
    "\n",
    "#     img=(np.clip(cv2.cvtColor(np.clip(image.numpy().transpose((1, 2, 0)),0,1), cv2.COLOR_RGB2BGR),0,1)*255).astype(np.uint8).copy()\n",
    "#     for predicted_class in predicted_classes:\n",
    "#         print(predicted_class)\n",
    "#         label=predicted_class[0]\n",
    "#         print(label)\n",
    "#         probability=predicted_class[1]\n",
    "#         print(probability)\n",
    "#         box=predicted_class[2]\n",
    "#         box1 = (int(box[0][0]), int(box[0][1]))\n",
    "        \n",
    "#         box2 = (int(box[1][0]), int(box[1][1]))\n",
    "        \n",
    "#         cv2.rectangle(img, box1, box2,(0, 255, 0), 3) # Draw Rectangle with the coordinates\n",
    "# #         cv2.rectangle(img,(384,0),(510,128),(0,255,0),3)\n",
    "\n",
    "#         cv2.putText(img,label, box1,  cv2.FONT_HERSHEY_SIMPLEX, text_size, (255,0,0),thickness=3) \n",
    "#         cv2.putText(img,label+\": \"+str(round(probability*100,2))+\" %\", box1,  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,0,255),thickness=3)\n",
    "#         plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predictions(pred,threshold=0.8,objects=None ):\n",
    "#     \"\"\"\n",
    "#     This function will assign a string name to a predicted class and eliminate predictions whose likelihood  is under a threshold \n",
    "    \n",
    "#     pred: a list where each element contains a tuple that corresponds to information about  the different objects; Each element includes a tuple with the class yhat, probability of belonging to that class and the coordinates of the bounding box corresponding to the object \n",
    "#     image : frozen surface\n",
    "#     predicted_classes: a list where each element contains a tuple that corresponds to information about  the different objects; Each element includes a tuple with the class name, probability of belonging to that class and the coordinates of the bounding box corresponding to the object \n",
    "#     thre\n",
    "#     \"\"\"\n",
    "\n",
    "\n",
    "#     predicted_classes= [(COCO_INSTANCE_CATEGORY_NAMES[i],p,[(box[0], box[1]), (box[2], box[3])]) for i,p,box in zip(list(pred[0]['labels'].numpy()),pred[0]['scores'].detach().numpy(),list(pred[0]['boxes'].detach().numpy()))]\n",
    "#     predicted_classes=[  stuff  for stuff in predicted_classes  if stuff[1]>threshold ]\n",
    "    \n",
    "#     if objects  and predicted_classes :\n",
    "#         predicted_classes=[ (name, p, box) for name, p, box in predicted_classes if name in  objects ]\n",
    "#     return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d4f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
